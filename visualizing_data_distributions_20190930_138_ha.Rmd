---
title: "**Chapter 9. Visualizing data distribution**"
output: html_notebook
---

## **9.1 Variable types**

We will be working with two types of variables: categorical and numeric. Example of numerical data are population sizes, murder rates, and heights.

## **9.2 Case study: describing student heights**
```{r}
library(tidyverse)
library(dslabs)
data(heights)
head(heights)
```

## **9.3 Distribution function**

The most basic statistical summary of a list of objects or numbers is its distribution. The simplest way to think of a distribution is as a compact description of a list with many entries.
```{r}
#> Female   Male 
#>  0.227  0.773
```

## **9.4 Cumulative distribution functions**

In general, when data is not categorical, reporting the frequency of each entry is not an effective summary since most entries are unique.
$$ F(a)=Pr(x<=a) $$

## **9.5 Histograms**

The simplest way to make a histogram is to divide the span of our data into non-overlapping bins of the same size. Then, for each bin, we count the number of values that fall in that interval. The histogram plots these counts as bars with the base of the bar defined by the intervals.

## **9.6 Smoothed density**

Smooth density plots are aesthetically more appealing than histograms. We no longer have sharp edges at the interval boundaries and many of the local peaks have been removed.

The main new concept you must understand is that we assume that our list of observed values is a subset of a much larger list of unobserved values.

We need to make this choice with care as the resulting visualizations can change our interpretation of the data. We should select a degree of smoothness that we can defend as being representative of the underlying data.

### **9.6.1 Interpreting the y-axis**

If you imagine we form a bin with a base 1 unit in length, the y-axis value tells us the proportion of values in that bin. However, this is only true for bins of size 1. For other size intervals, the best way to determine the proportion of data in that interval is by computing the proportion of the total area contained in that interval.

### **9.6.2 Densities permit stratification**

We point out that an advantage of smooth densities over histograms for visualization purposes is that densities makes it easier to compare two distributions.

## **9.7 Exercises**

**1. In the `murder` dataset, the region is a categorical variable and the following is its distribution: To the closet 5%, what proportion of the states are in the North Central region?**

https://rafalab.github.io/dsbook/book_files/figure-html/barplot-exercise-1.png
```{r}
data(murders)
murders %>% filter(region == 'North Central')
```


**2. Which of the following is true:**

A. The graph above is a histogram.

B. The graph above shows only four numbers with a bar plot.

**C. Categories are not numbers, so it does not make sense to graph the distribution.**

D. The colors, not the height of the bars, describe the distribution.


**3. The plot below shows the eCDF for male heights: Based on the plot, what percentage of males are shorter than 75 inches?**

https://rafalab.github.io/dsbook/book_files/figure-html/ecdf-exercise-1.png

A. 100%

**B. 95%**

C. 80%

D. 72 inches


**4. To the closet inch, what height `m` has the property that 1/2 of the male students are taller than `m` and 1/2 are shorter?**

A. 61 inches

B. 64 inches

**C. 69 inches**

D. 74 inches


**5. Here is an eCDF of the murder rates across states: Knowing that there are 51 states (counting DC) and based on this plot, how many states have murder rates larger than 10 per 100,000 people?**

https://rafalab.github.io/dsbook/book_files/figure-html/ecdf-exercise-2-1.png

A. 1

B. 5

C. 10

**D. 50**


**6. Based on the eCDF above, which of the following statements are true:**

A. About half the states have murder rates above 7 per 100,000 and the other half below.

B. Most states have murder rates below 2 per 100,000.

C. All the states have murder rates above 2 per 100,000.

**D. With the exception of 4 states, the murder rates are below 5 per 100,000.**


**7. Below is a histogram of male heights in our `height` dataset:**

https://rafalab.github.io/dsbook/book_files/figure-html/height-histogram-exercise-1.png

Based on this plot, how many males are between 63.5 and 65.5?

A. 10

B. 24

**C. 34**

D. 100


**8. About what percentage are shorter than 60 inches?**

**A. 1%**

B. 10%

C. 25%

D. 50%

**9. Based on the density plot below, about what proportion of US states have populations larger than 10 million?**

https://rafalab.github.io/dsbook/book_files/figure-html/density-exercise-1.png

A. 0.02

B. 0.15

C. 0.50

**D. 0.55**

**10. Below are three density plots. Is it possible that they are from the same dataset?**

A. It is impossible that they are from the same dataset.

B. They are from the same dataset, but the plots are different due to code errors.

C. They are the same dataset, but the first and second plot undersmooth and the third oversmooths.

**D. They are the same dataset, but the first is not in the log scale, the second undersmooths and the third oversmooths.**

## **9.8 The normal distribution**

The normal distribution, also known as the bell curve and as the Gaussian distribution, is one of the most famous mathematical concepts in history. A reason for this is that approximately normal distributions occur in many situations, including gambling winnings, heights, weights, blood pressure, standardized test scores, and experimental measurement errors.

The distribution is symmetric, centered at the average, and most values (about 95%) are within 2 SDs from the average.

For a list of numbers contained in a vector `x`, the average is defined as:
```{r}
m  <- sum(x) / length(x)
```
the standard deviation is defined as:
```{r}
s <- sqrt(sum((x-mu)^2) / length(x))
```
compute the values for the height for males which we will store in the object *x*:
```{r}
index <- heights$sex=="Male"
x <- heights$height[index]
```

`sd`는 `length(x)`대신 `length(x)-1`로 나눠질 수도 있다:
```{r}
m <- mean(x)
s <- sd(x)
c(average = m, sd = s)
```

## **9.9 Standard units**

For data that is approximately normally distributed, it is convenient to think in terms of *standard units*. Specifically, for a value `x` from a vector `X`, we define the value of `x` in standard units as `z = (x - m)/s` with `m` and `s` the average and standard deviation of `X` respectively.

First look back at the formula for the normal distribution and note that what is being exponentiated is `-z^2/2` with `z` equivalent to `x` in standard units. Because the maximum of `e^(-z^2/2)` is when `z=0`, this explains why the maximum of the distribution occurs at the average. It also explains the symmetry since `-z^2/2` is symmetric around 0. Second, note that if we convert the normally distributed data to standard units, we can quickly know if, for example, a person is about average (z=0), one of the largest (z≈2), one of the smallest (z≈−2) or an extremely rare occurrence (z>3 or z<−3).

In R, we can obtain standard units using the function `scale`:
```{r}
z <- scale(x)
```
Now to see how many men are within 2 SDs from the average, we simply type:
```{r}
mean(abs(z) < 2)
```

## **9.10 Quantile-quantile plots**

A systematic way to assess how well the normal distribution fits the data is to check if the observed and predicted proportions match. In general, this is the approach of the **quantile-quantile plot** (QQ-plot).

First let’s define the theoretical quantiles for the normal distribution. In statistics books we use the symbol `Φ(x)` to define the function that gives us the probability of a standard normal distribution being smaller than `x`. So, for example, `Φ(−1.96)=0.025` and `Φ(1.96)=0.975`. In R, we can evaluate `Φ` using the `pnorm` function:
```{r}
pnorm(-1.96)
```
The inverse function `Φ^−1(x)` gives us the theoretical quantiles for the normal distribution. So, for example, 'Φ^−1(0.975)=1.96`. In R, we can evaluate the inverse of `Φ` using the `qnorm` function.
```{r}
qnorm(0.975)
```
Note that these calculations are for the standard normal distribution by default (mean = 0, standard deviation = 1), but we can also define these for any normal distribution. For example, we can use `qnorm` to determine quantiles of a distribution with a specific average and standard deviation:
```{r}
qnorm(0.975, mean = 5, sd = 2)
```
Using R code, we can define `q` as the value for which` mean(x <= q) = p`. Notice that not all *p* have a *q* for which the proportion is exactly *p*. There are several ways of defining the best *q* as discussed in the help for the `quantile` function.

```{r}
# For example,
mean(x <= 69.5)
```
So about 50% are shorter or equal to 69 inches. This implies that if *p=0.50* then *q=69.5*.

To construct a QQ-plot, we do the following:

1. Define a vector of *m* proportions p1, p2, ..., pm.

2. Define a vector of quantiles q1, ..., qm for your data for the proportions p1, ..., pm. We refer to these as the *sample quantiles*.

3. Define a vector of theoretical quantiles for the proportions p1, ..., pm for a normal distribution with the same average and standard deviation as the data.

4. Plot the sample quantiles versus the theoretical quantiles.

Let’s construct a QQ-plot using R code. Start by defining the vector of proportions.
```{r}
p <- seq(0.05, 0.95, 0.05)
```
To obtain the quantiles from the data, we can use the `quantile` function like this:
```{r}
sample_quantiles <- quantile(x, p)
```
To obtain the theoretical normal distribution quantiles with the corresponding average and SD, we use the `qnorm` function:
```{r}
theoretical_quantiles <- qnorm(p, mean=mean(x), sd=sd(x))
```
To see if they match or not, we plot them against each other and draw the identity line:
```{r}
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
```
Notice that this code becomes much cleaner if we use standard units:
```{r}
sample_quantiles <- quantile(z, p)
theoretical_quantiles <- qnorm(p) 
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
```
However, in practice it is easier to use the **ggplot2** code described in Section 9.16:
```{r}
heights %>% filter(sex=="Male") %>%
  ggplot(aes(sample = scale(height))) + 
  geom_qq() +
  geom_abline()
```

## **9.11 Percentiles**

*Percentiles* are special cases of *quantiles* that are commonly used. The percentiles are he quantiles you obtain when setting the p at 0.01, 0.02, ..., 0.99. We call, for example, the case of p=0.25 the 25th percentile, which gives us a number for which 25% of the data is below. The most famous percentile is the 50th, also known as the *median*.

## **9.12 Boxplots**

Provide a five-number summary composed of the range along with the quartiles (the 25th, 50th, and 75th percentiles). Tukey further suggested that we ignore outliers when computing the range and instead plot these as independent points.

With the box defined by the 25% and 75% percentile and the whiskers showing the range. The distance between these two is called the interquartile range. The two points are outliers according to Tukey’s definition. The median is shown with a horizontal line. Today, we call these boxplots.

## **9.13 Stratification**

In data analysis we often divide observations into groups based on the values of one or more variables associated with those observations. For example in the next section we divide the height values into groups based on a sex variable: females and males. We call this procedure *stratification* and refer to the resulting groups as *strata*.

## **9.14 Case study: describing student heights (continued)**

Using the histogram, density plots and QQ-plots, we have become convinced that the male height data is well approximated with a normal distribution. 

Regarding the five smallest values, note that these values are:
```{r}
heights %>% filter(sex=="Female") %>% top_n(5, desc(height)) %>% pull(height)
```

## **9.15 Exercises**

**1. Define variables containing the heights of males and females like this:**
```{r}
library(dslabs)
data(heights)
male <- heights$height[heights$sex=="Male"]
female <- heights$height[heights$sex=="Female"]
```
**How many measurements do we have for each?**
```{r}
length(male)
length(female)
```

**2. Suppose we can’t make a plot and want to compare the distributions side by side. We can’t just list all the numbers. Instead, we will look at the percentiles. Create a five row table showing `female_percentiles` and `male_percentiles` with the 10th, 30th, 50th, …, 90th percentiles for each sex. Then create a data frame with these two as columns.**
```{r}
p <- seq(0.1, 0.9, 0.2)
female_percentiles <- quantile(female, p)
male_percentiles <- quantile(male, p)

data.frame(male_percentiles, female_percentiles)
```

**3. Study the following boxplots showing population sizes by country:**

https://rafalab.github.io/dsbook/book_files/figure-html/boxplot-exercise-1.png

**Which continent has the country with the biggest population size?**

> Asia

**4. What continent has the largest median populatin size?**

> Africa

**5. What is median population size for Africa to the nearest million?**

> 10 million

**6. What proportion of countries in Europe have population below 14 million?**

A. 0.99

**B. 0.75**

C. 0.50

D. 0.25

**7. If we use a log transformation, which continent shown above has the largest interquartile range?**

> Americas

**8. Load the height data set and create a vector `x` with just the male heights:**
```{r}
library(dslabs)
data(heights)
x <- heights$height[heights$sex=="Male"]
```
**What proportion of the data is between 69 and 72 inches (taller than 69, but shorter or equal to 72)? Hint: use a logical operator and `mean`.**
```{r}
mean(x > 69 & x < 72) 
```

**9. Suppose all you know about the data is the average and the standard deviation. Use the normal approximation to estimate the proportion you just calculated. Hint: start by computing the average and standard deviation. Then use the `pnorm` function to predict the proportions.**
```{r}
avg <- mean(x)
sd <- sd(x)
# pnorm()으로 어떻게 proportion을 prediction?
```

**10. Notice that the approximation calculated in question two is very close to the exact calculation in the first question. Now perform the same task for more extreme values. Compare the exact calculation and the normal approximation for the interval (79,81]. How many times bigger is the actual proportion than the approximation?**
```{r}
mean(x > 79 & x <= 81)
# pnorm 사용법
```

**11. Approximate the distribution of adult men in the world as normally distributed with an average of 69 inches and a standard deviation of 3 inches. Using this approximation, estimate the proportion of adult men that are 7 feet tall or taller, referred to as seven footers. Hint: use the `pnorm` function.**


**12. There are about 1 billion men between the ages of 18 and 40 in the world. Use your answer to the previous question to estimate how many of these men (18-40 year olds) are seven feet tall or taller in the world?**


**13. There are about 10 National Basketball Association (NBA) players that are 7 feet tall or higher. Using the answer to the previous two questions, what proportion of the world’s 18 to 40 year old seven footers are in the NBA?**

**14. Repeat the calculations performed in the previous question for Lebron James’ height: 6 feet 8 inches. There are about 150 players that are at least that tall.**


**15. In answering the previous questions, we found that it is not at all rare for a seven footer to become an NBA player. What would be a fair critique of our calculations:**

A. Practice and talent are what make a great basketball player, not height.

B. The normal approximation is not appropriate for heights.

C. As seen in question 3, the normal approximation tends to underestimate the extreme values. It’s possible that there are more seven footers than we predicted.

D. As seen in question 3, the normal approximation tends to overestimate the extreme values. It’s possible that there are less seven footers than we predicted.

## **9.16 ggplot2 geometries**

### **9.16.1 Barplots**

To generate a barplot we can use the `geom_bar` geometry. The default is to count the number of each category and draw a bar. Here is the plot for the regions of the US.
```{r}
murders %>% ggplot(aes(region)) + geom_bar()
```
We often already have a table with a distribution that we want to present as barplot. Here is an example such a table:
```{r}
data(murders)
tab <- murders %>% 
  count(region) %>% 
  mutate(proportion = n/sum(n))
tab
```
We no longer want `geom_bar` to count, but rather just plot a bar to the height provided by the `proportion` variable. For this we need to provide `x` (the categories) and `y` (the values) and use the `stat="identity"` option.
```{r}
tab %>% ggplot(aes(region, proportion)) + geom_bar(stat = "identity")
```

### **9.16.2 Histograms**

To generate histograms we use `geom_histogram`. By looking at the help file for this function, we learn that the only required argument is `x`, the variable for which we will construct a histogram.
```{r}
heights %>% 
  filter(sex == "Female") %>% 
  ggplot(aes(height)) + 
  geom_histogram()
```
```{r}
heights %>% 
  filter(sex == "Female") %>% 
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, fill = "blue", col = "black") +
  xlab("Male heights in inches") + 
  ggtitle("Histogram")
```

### **9.16.3 Density plots**

To create a smooth density, we use the `geom_density`. Here the is data previously shown as a histogram:
```{r}
heights %>% 
  filter(sex == "Female") %>%
  ggplot(aes(height)) +
  geom_density(fill="blue")
```
To change the smoothness of the density, we use the `adjust` argument to multiply the default value by that `adjust`.
```{r}
heights %>% 
  filter(sex == "Female") %>%
  ggplot(aes(height)) +
  geom_density(fill="blue", adjust = 2)
```

### **9.16.4 Boxplots**

The geometry for boxplot is `geom_boxplot`. As discussed, boxplots are useful for comparing distributions. For example, below are the previously shown heights for women, but compared to men.

https://rafalab.github.io/dsbook/book_files/figure-html/female-male-boxplots-geom-1.png

### **9.16.5 QQ-plots**

For qq-plots we use the `geom_qq` geometry.
```{r}
heights %>% filter(sex=="Male") %>%
  ggplot(aes(sample = height)) +
  geom_qq()
```

By default, the sample variable is compared to a normal distribution with average 0 and standard deviation 1. To change this, we use the `dparams` arguments based on the help file. Adding an identity line is as simple as assigning another layer. For straight lines, we use the `geom_abline` function.
```{r}
params <- heights %>% filter(sex=="Male") %>%
  summarize(mean = mean(height), sd = sd(height))

heights %>% filter(sex=="Male") %>%
  ggplot(aes(sample = height)) +
  geom_qq(dparams = params) +
  geom_abline()
```
Another option here is to scale the data first and then make a qqplot against the standard normal.
```{r}
heights %>% 
  filter(sex=="Male") %>%
  ggplot(aes(sample = scale(height))) + 
  geom_qq() +
  geom_abline()
```

### **9.16.6 Images**

The two geometries used to create images: `geom_tile` and `geom_raster`. To create an image in ggplot2 we need a data frame with the x and y coordinates as well as the values associated with each of these. 
```{r}
x <- expand.grid(x = 1:12, y = 1:10) %>% 
  mutate(z = 1:120) 
```
Note that this is the tidy version of a matrix, `matrix(1:120, 12, 10)`. To plot the image we use the following code:
```{r}
x %>% ggplot(aes(x, y, fill = z)) + 
  geom_raster()
```
With these images you will often want to change the color scale. This can be done through the `scale_fill_gradientn` layer.
```{r}
x %>% ggplot(aes(x, y, fill = z)) + 
  geom_raster() + 
  scale_fill_gradientn(colors =  terrain.colors(10))
```

### **9.16.7 Quick plots**

We can also use qplot to make histograms, density plots, boxplot, qqplots and more. Although it does not provide the level of control as `ggplot`, `qplot` is definitely useful as it permits us to make a plot with a short snippet of code.
```{r}
x <- heights %>% 
  filter(sex=="Male") %>% 
  pull(height)
```
To make a quick histogram we can use:
```{r}
qplot(x)
# The function guesses that we want to make a histogram because we only supplied one variable.
```
To make a quick qqplot you have to use the `sample` argument. Note that we can add layers just as we do with `ggplot`.
```{r}
qplot(sample = scale(x)) + geom_abline()
```
If we supply a factor and a numeric vector, we obtain a plot like the below. Note that in the code below we are using the `data` argument.
```{r}
heights %>% qplot(sex, height, data = .)
```
We can also select a specific geometry by using the `geom` argument.
```{r}
heights %>% qplot(sex, height, data = ., geom = "boxplot")
```
We can also use the `geom` argument to generate a density plot instead of a histogram:
```{r}
qplot(x, geom = "density")
```
Although not as much as with `ggplot`, we do have some flexibility to improve the results of `qplot`.
```{r}
qplot(x, bins=15, color = I("black"), xlab = "Population")
```
**Technical note**: The reason we use `I("black")` is because we want `qplot` to treat `"black"` as a character rather than convert it to a factor, which is the default behavior within `aes`, which is internally called here. In general, the function `I` is used in R to say “keep it as it is”.

## **9.17 Exercises**

**1. Now we are going to use the `geom_histogram` function to make a histogram of the height in the `heights` data frame. When reading the documentation for this function we see that it requires just one mapping, the values to be used for the histogram. Make a histogram of all the plots.**

**What is the variable containing the heights?**

A. `sex`

B. `heights`

**C. `height`**

D. `heights$height`

**2. Now create a ggplot object using the pipe to assign the heights data to a ggplot object. Assign height to the x values through the aes function.**
```{r}
heights %>%
  ggplot(aes(height))
```

**3. Now we are ready to add a layer to actually make the histogram. Use the object created in the previous exercise and the geom_histogram function to make the histogram.**
```{r}
heights %>%
  ggplot(aes(height)) +
  geom_histogram()
```

**4. Note that when we run the code in the previous exercise we get the warning: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.**

**Use the `binwidth` argument to change the histogram made in the previous exercise to use bins of size 1 inch.**
```{r}
heights %>%
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1)
```

**5. Instead of a histogram, we are going to make a smooth density plot. In this case we will not make an object, but instead render the plot with one line of code. Change the geometry in the code previously used to make a smooth density instead of a histogram.**
```{r}
heights %>%
  ggplot(aes(height)) +
  geom_density()
```

**6. Now we are going to make a density plot for males and females separately. We can do this using the `group` argument. We assign groups via the aesthetic mapping as each point needs to a group before making the calculations needed to estimate a density.**
```{r}
heights %>% 
  ggplot(aes(height, group = sex)) + 
  geom_density() 
```

**7. We can also assign groups through the `color` argument. This has the added benefit that it uses color to distinguish the groups. Change the code above to use color.**
```{r}
heights %>% 
  ggplot(aes(height, color = sex)) + 
  geom_density()
```


**8. We can also assign groups through the fill argument. This has the added benefit that it uses colors to distinguish the groups, like this:**
```{r}
heights %>% 
  ggplot(aes(height, fill = sex)) + 
  geom_density() 
```
However, here the second density is drawn over the other. We can make the curves more visible by using alpha blending to add transparency. Set the alpha parameter to 0.2 in the `geom_density` function to make this change.
```{r}
heights %>% 
  ggplot(aes(height, fill = sex)) + 
  geom_density(alpha=0.2) 
```

