---
title: "**Chapter 13 Probability**"
output: html_notebook
---

Probability theory is useful in many other contexts and, in particular, in areas that depend on data affected by chance in some way. All of the other chapters in this part build upon probability theory.

## **13.1 Discrete probability**

We start by covering some basic principles related to categorical data. The subset of probability is referred to as *discrete probability*.

### 13.1.1 Relative frequency

If I have 2 red beads and 3 blue beads inside an urn47 (most probability books use this archaic term, so we do too) and I pick one at random, what is the probability of picking a red one? Our intuition tells us that the answer is 2/5 or 40%. A precise definition can be given by noting that there are five possible outcomes of which two satisfy the condition necessary for the event “pick a red bead”. Since each of the five outcomes has the same chance of occurring, we conclude that the probability is .4 for red and .6 for blue.

A more tangible way to think about the probability of an event is as the proportion of times the event occurs when we repeat the experiment an infinite number of times, independently, and under the same conditions.

### 13.1.2 Notation

We use the notation Pr(A) to denote the probability of event A happening. We use the very general term event to refer to things that can happen when something occurs by chance. In data science applications, we will often deal with continuous variables.

### 13.1.3 Probability distributions

If we know the relative frequency of the different categories, defining a distribution for categorical outcomes is relatively straightforward. We simply assign a probability to each category. In cases that can be thought of as beads in an urn, for each bead type, their proportion defines the distribution.

## **13.2 Monte Carlo simulations for categorical data**

Computers provide a way to actually perform the simple random experiment described above: pick a bead at random from a bag that contains three blue beads and two red ones. Random number generators permit us to mimic the process of picking at random.

```{r}
beads <- rep(c("red", "blue"), times = c(2,3))
beads
```
and then use `sample` to pick a bead at random:
```{r}
sample(beads, 1)
```
This line of code produces one random outcome. We want to repeat this experiment an infinite number of times, but it is impossible to repeat forever. Instead, we repeat the experiment a large enough number of times to make the results practically equivalent to repeating forever. **This is an example of a Monte Carlo simulation**.

Much of what mathematical and theoretical statisticians study, which we do not cover in this book, relates to providing rigorous definitions of “practically equivalent” as well as studying how close a large number of experiments gets us to what happens in the limit.

To perform our first Monte Carlo simulation, we use the `replicate` function, which permits us to repeat the same task any number of times. Here, we repeat the random event **B=10,000** times:
```{r}
B <- 10000
events <- replicate(B, sample(beads, 1))
```
We can now see if our definition actually is in agreement with this Monte Carlo simulation approximation. We can use `table` to see the distribution:
```{r}
tab <- table(events)
tab
```
and `prop.table` gives us the proportions:
```{r}
prop.table(tab)
```
Although this is a simple and not very useful example, we will use Monte Carlo simulations to estimate probabilities in cases in which it is harder to compute the exact ones.

### 13.2.1 Setting the random seed
```{r}
set.seed(1986) 
```
Many of the results presented can actually change by chance, which then suggests that a frozen version of the book may show a different result than what you obtain when you try to code as shown in the book. This is actually fine since the results are random and change from time to time. However, if you want to ensure that results are exactly the same every time you run them, you can set R’s random number generation seed to a specific number.

### 13.2.2 With and without replacement

The function `sample` has an argument that permits us to pick more than one element from the urn. However, by default, this selection occurs *without replacement*: after a bead is selected, it is not put back in the bag.
```{r}
sample(beads, 5)
sample(beads, 5)
```
This results in rearrangements that always have three blue and two red beads. If we ask that six beads be selected, we get an error:
```{r}
sample(beads, 6)
```
However, the `sample` function can be used directly, without the use of `replicate`, to repeat the same experiment of picking 1 out of the 5 beads, continually, under the same conditions. To do this, we sample with replacement: return the bead back to the urn after selecting it. We can tell `sample` to do this by changing the `replace` argument, which defaults to `FALSE`, to `replace = TRUE`:
```{r}
events <- sample(beads, B, replace = TRUE)
prop.table(table(events))
```

## **13.3 Independence**

We say two events are independent if the outcome of one does not affect the other. The classic example is coin tosses. Many examples of events that are not independent come from card games. Now if we deal a King for the first card, and don’t replace it into the deck, the probabilities of a second card being a King is less because there are only three Kings left: the probability is 3 out of 51. These events are therefore **not independent**: the first outcome affected the next one.
```{r}
x <- sample(beads, 5)
x[2:5]
```

## **13.4 Conditional probabilities**

When events are not independent, *conditional probabilities* are useful. We already saw an example of a conditional probability:

We use the ∣ as shorthand for “given that” or “conditional on”. When two events, say A and B, are independent, we have: 

$$ Pr(A∣B)=Pr(A)$$

## **13.5 Addition and multiplication rules**

### 13.5.1 Multiplication rule

If we want to know the probability of two events, say A and B, occurring, we can use the multiplication rule:

$$ Pr(A and B)=Pr(A)Pr(B∣A)$$

The multiplication rule also applies to more than two events. We can use induction to expand for more events:

### 13.5.2 Multiplication rule under independence

When we have independent events, then the multiplication rule becomes simpler:

$$ Pr(A and B and C)=Pr(A)Pr(B)Pr(C)$$
But we have to be very careful before using this since assuming independence can result in very different and incorrect probability calculations when we don’t actually have independence.

The multiplication rule also gives us a general formula for computing conditional probabilities:

$$ Pr(B∣A)=Pr(A and B)/Pr(A) $$

### 13.5.3 Addition rule

The addition rule tells us that:

$$ Pr(A or B)=Pr(A)+Pr(B)-Pr(A and B) $$

## **13.6 Combinations and permutations**

What is the probability that if I draw five cards without replacement, I get all cards of the same suit, what is known as a “flush” in poker? In a discrete probability course you learn theory on how to make these computations.

First, let’s construct a deck of cards. For this, we will use the `expand.grid` and paste functions. We use paste to create strings by joining smaller strings. To do this, we take the number and suit of a card and create the card name like this:
```{r}
number <- "Three"
suit <- "Hearts"
paste(number, suit)
```
`paste` also works on pairs of vectors performing the operation element-wise:
```{r}
paste(letters[1:5], as.character(1:5))
```
The function `expand.grid` gives us all the combinations of entries of two vectors. For example, if you have blue and black pants and white, grey, and plaid shirts, all your combinations are:
```{r}
expand.grid(pants = c("blue", "black"), shirt = c("white", "grey", "plaid"))
```
Here is how we generate a deck of cards:
```{r}
suits <- c("Diamonds", "Clubs", "Hearts", "Spades")
numbers <- c("Ace", "Deuce", "Three", "Four", "Five", "Six", "Seven", 
             "Eight", "Nine", "Ten", "Jack", "Queen", "King")
deck <- expand.grid(number=numbers, suit=suits)
deck <- paste(deck$number, deck$suit)
```

With the deck constructed, we can double check that the probability of a King in the first card is 1/13 by computing the proportion of possible outcomes that satisfy our condition:
```{r}
kings <- paste("King", suits)
mean(deck %in% kings)
```
We can use the `permutations` function from the **gtools** package. For any list of size `n`, this function computes all the different combinations we can get when we select `r` items.
```{r}
library(gtools)
permutations(3, 2)
```
Optionally, we can add a vector. If you want to see five random seven digit phone numbers out of all possible phone numbers (without repeats), you can type:
```{r}
all_phone_numbers <- permutations(10, 7, v = 0:9)
n <- nrow(all_phone_numbers)
index <- sample(n, 5)
all_phone_numbers[index,]
```
Instead of using the numbers 1 through 10, the default, it uses what we provided through `v`: the digits 0 through 9.
```{r}
hands <- permutations(52, 2, v = deck)
```
This is a matrix with two columns and 2652 rows. With a matrix we can get the first and second cards like this:
```{r}
first_card <- hands[,1]
second_card <- hands[,2]
```
Now the cases for which the first hand was a King can be computed like this:
```{r}
kings <- paste("King", suits)
sum(first_card %in% kings)
```
To get the conditional probability, we compute what fraction of these have a King in the second card:
```{r}
sum(first_card%in%kings & second_card%in%kings) / sum(first_card%in%kings)
```
Notice that the code above is equivalent to:
```{r}
mean(first_card%in%kings & second_card%in%kings) / mean(first_card%in%kings)
```
If we wanted to compute the probability of this happening, we would enumerate the combinations, not the permutations, since the order does not matter.
```{r}
combinations(3,2)
```
In the second line, the outcome does not include (2,1) because (1,2) already was enumerated. The same applies to (3,1) and (3,2).

So to compute the probability of a Natural 21 in Blackjack, we can do this:
```{r}
aces <- paste("Ace", suits)

facecard <- c("King", "Queen", "Jack", "Ten")
facecard <- expand.grid(number = facecard, suit = suits)
facecard <- paste(facecard$number, facecard$suit)

hands <- combinations(52, 2, v = deck)
mean(hands[,1] %in% aces & hands[,2] %in% facecard)
```
In the last line, we assume the Ace comes first. This is only because we know the way combination enumerates possibilities and it will list this case first.
```{r}
mean((hands[,1] %in% aces & hands[,2] %in% facecard) |
       (hands[,2] %in% aces & hands[,1] %in% facecard))
```

### 13.6.1 Monte Carlo example

Instead of using `combinations` to deduce the exact probability of a Natural 21, we can use a Monte Carlo to estimate this probability.
```{r}
hand <- sample(deck, 2)
hand
```
Going forward, we include 10 when we say face card. Now we need to check both possibilities:
```{r}
(hands[1] %in% aces & hands[2] %in% facecard) | 
  (hands[2] %in% aces & hands[1] %in% facecard)
```
Let’s start by writing a function that draws a hand and returns TRUE if we get a 21. The function does not need any arguments because it uses objects defined in the global environment.
```{r}
blackjack <- function(){
   hand <- sample(deck, 2)
  (hand[1] %in% aces & hand[2] %in% facecard) | 
    (hand[2] %in% aces & hand[1] %in% facecard)
}
```
Here we do have to check both possibilities: Ace first or Ace second because we are not using the `combinations` function.
```{r}
blackjack()
```
Now we can play this game, say, 10,000 times:
```{r}
B <- 10000
results <- replicate(B, blackjack())
mean(results)
```

## **13.7 Examples**

### 13.7.1 Monty Hall problem

We can use probability to show that if you stick with the original door choice, your chances of winning a prize remain 1 in 3. However, if you switch to the other door, your chances of winning double to 2 in 3! This seems counterintuitive. Many people incorrectly think both chances are 1 in 2 since you are choosing between 2 options. You can watch a detailed mathematical explanation on Khan Academy or read one on Wikipedia. Below we use a Monte Carlo simulation to see which strategy is better. Note that this code is written longer than it should be for pedagogical purposes.
```{r}
B <- 10000
monty_hall <- function(strategy){
  doors <- as.character(1:3)
  prize <- sample(c("car", "goat", "goat"))
  prize_door <- doors[prize == "car"]
  my_pick  <- sample(doors, 1)
  show <- sample(doors[!doors %in% c(my_pick, prize_door)],1)
  stick <- my_pick
  stick == prize_door
  switch <- doors[!doors%in%c(my_pick, show)]
  choice <- ifelse(strategy == "stick", stick, switch)
  choice == prize_door
}

stick <- replicate(B, monty_hall("stick"))
mean(stick)

switch <- replicate(B, monty_hall("switch"))
mean(switch)
```
From this we should realize that the chance is 1 in 3, what we began with. When we switch, the Monte Carlo estimate confirms the 2/3 calculation. This helps us gain some insight by showing that we are removing a door, `show`, that is definitely not a winner from our choices.

### 13.7.2 Birthday problem

Suppose you are in a classroom with 50 people. If we assume this is a randomly selected group of 50 people, what is the chance that at least two people have the same birthday?

First, note that birthdays can be represented as numbers between 1 and 365, so a sample of 50 birthdays can be obtained like this:
```{r}
n <- 50
bdays <- sample(1:365, n, replace = TRUE)
```
To check if in this particular set of 50 people we have at least two with the same birthday, we can use the function `duplicated`, which returns `TRUE` whenever an element of a vector is a duplicate. Here is an example:
```{r}
duplicated(c(1,2,3,1,4,3,5))
```
The second time 1 and 3 appear, we get a `TRUE`. So to check if two birthdays were the same, we simply use the `any` and `duplicated` functions like this:
```{r}
any(duplicated(bdays))
```
To estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 50 birthdays over and over:
```{r}
B <- 10000
same_birthday <- function(n){
  bdays <- sample(1:365, n, replace=TRUE)
  any(duplicated(bdays))
}
results <- replicate(B, same_birthday(50))
mean(results)
```
Say we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?
```{r}
compute_prob <- function(n, B=10000){
  results <- replicate(B, same_birthday(n))
  mean(results)
}
```

Using the function `sapply`, we can perform element-wise operations on any function:
```{r}
n <- seq(1,60)
prob <- sapply(n, compute_prob)
```
We can now make a plot of the estimated probabilities of two people having the same birthday in a group of size *n*:
```{r}
library(tidyverse)
prob <- sapply(n, compute_prob)
qplot(n, prob)
```

Now let’s compute the exact probabilities rather than use Monte Carlo approximations. We can write a function that does this for any number:
```{r}
exact_prob <- function(n){
  prob_unique <- seq(365,365-n+1)/365 
  1 - prod( prob_unique)
}
eprob <- sapply(n, exact_prob)
qplot(n, prob) + geom_line(aes(n, eprob), col = "red")
```

This plot shows that the Monte Carlo simulation provided a very good estimate of the exact probability. 

## **13.8 Infinity in practice**

One practical approach we will describe here is to check for the stability of the estimate. The following is an example with the birthday problem for a group of 25 people.
```{r}
B <- 10^seq(1, 5, len = 100)
compute_prob <- function(B, n=25){
  same_day <- replicate(B, same_birthday(n))
  mean(same_day)
}
prob <- sapply(B, compute_prob)
qplot(log10(B), prob, geom = "line")
```

## **13.9 Exercises**

**1. One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?**
```{r}
balls <- rep(c("cyan", "magenta", "yellow"), times = c(3,5,7))
B <- 10000
cyan <- replicate(B, balls %in% "cyan")
mean(cyan)
```

**2 What is the probability that the ball will not be cyan?**
```{r}
not_cyan <- replicate(B, !balls %in% "cyan")
mean(not_cyan)
```

**3. Instead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling without replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?**
```{r}

```


**4. Now repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling with replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?**
```{r}

```


**5. Two events A and B are independent if Pr(A and B)=Pr(A)Pr(B). Under which situation are the draws independent?**

A. You don't replace the draw.
**B. You replace the draw.**
C. Neither
D. Both

**6. Say you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?**

**7. If you roll a 6-sided die six times, what is the probability of not seeing a 6?**

**8. Two teams, say the Celtics and the Cavs, are playing a seven game series. The Cavs are a better team and have a 60% chance of winning each game. What is the probability that the Celtics win at least one game?**

**9. Create a Monte Carlo simulation to confirm your answer to the previous problem. Use `B <- 10000` simulations. Hint: use the following code to generate the results of the first four games. The Celtics must win one of these 4 games.**
```{r}
celtic_wins <- sample(c(0,1), 4, replace = TRUE, prob = c(0.6, 0.4))
```

**10. Two teams, say the Cavs and the Warriors, are playing a seven game championship series. The first to win four games, therefore, wins the series. The teams are equally good so they each have a 50-50 chance of winning each game. If the Cavs lose the first game, what is the probability that they win the series?**

**11. Confirm the results of the previous question with a Monte Carlo simulation.**

**12. Two teams, A and B are playing a seven game series. Team A is better than team B adn has a p > 0.5 chance of winning each game. Given a value p the probability of winning the series for the underdog team B can be computed with the following function based on a Monte Carlo simulation:**
```{r}
prob_win <- function(p){
  B <- 10000
  result <- replicate(B, {
    b_win <- sample(c(1,0), 7, replace = TRUE, prob = c(1-p, p))
    sum(b_win)>=4
  })
  mean(result)
}
```
Use the function `sapply` to compute the probability, call it `Pr`, of winning for `p <- seq(0.5, 0.95, 0.025)`. Then plot the result.

**13. Repeat the exercise above, but now keep the probability fixed at `p <- 0.75` and compute the probability for different series lengths: best of 1 game, 3 games, 5 games,… Specifically, `N <- seq(1, 25, 2)`. Hint: use this function:**
```{r}
prob_win <- function(N, p=0.75){
  B <- 10000
  result <- replicate(B, {
    b_win <- sample(c(1,0), N, replace = TRUE, prob = c(1-p, p))
    sum(b_win)>=(N+1)/2
  })
  mean(result)
}
```

